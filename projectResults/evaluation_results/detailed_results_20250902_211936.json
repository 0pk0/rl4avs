{
  "A2C": {
    "algorithm": "A2C",
    "n_episodes": 50,
    "success_rate": 0.92,
    "collision_rate": 0.08,
    "mean_reward": 74.890247384997,
    "std_reward": 24.018901184563536,
    "mean_episode_length": 39.16,
    "mean_completion_time": 41.67391304347826,
    "mean_safety_achievement_time": 1.0,
    "reward_per_step": 1.912416940372753,
    "evaluation_time_seconds": 33.540337800979614,
    "consecutive_safe_episodes_max": 3,
    "total_successful_completions": 46,
    "total_collisions": 4,
    "mean_distance_traveled": 0.0,
    "raw_episode_rewards": [
      79.23617096704496,
      79.23617096704496,
      -9.871755254005038,
      79.10385023399581,
      79.23617096704496,
      79.10062624289091,
      91.53699221263932,
      79.10280182962927,
      79.10681069742407,
      79.11720953729306,
      79.11720953729306,
      79.23617096704496,
      79.11720953729306,
      79.23617096704496,
      79.23617096704496,
      77.79234401703258,
      114.39701378127282,
      77.76070615149936,
      78.93617096704496,
      -9.923876036535695,
      77.92538546403237,
      79.23617096704496,
      79.10316625908393,
      79.10385023399581,
      79.23617096704496,
      78.93617096704496,
      77.79234401703258,
      79.18110555408276,
      79.11384054997333,
      78.98999409817579,
      80.4117653520773,
      79.23617096704496,
      79.23617096704496,
      93.53833849830824,
      77.79234401703258,
      6.532184280794647,
      79.11720953729306,
      79.23617096704496,
      91.95995813691357,
      79.23617096704496,
      83.90194016906104,
      79.23617096704496,
      78.9903511924698,
      94.93944161485291,
      79.23617096704496,
      93.14582348446713,
      0.30490858165944523,
      79.06780481849844,
      79.23617096704496,
      91.72856446255847
    ],
    "raw_episode_lengths": [
      44,
      44,
      5,
      44,
      44,
      44,
      31,
      44,
      44,
      44,
      44,
      44,
      44,
      44,
      44,
      43,
      31,
      43,
      44,
      5,
      43,
      44,
      44,
      44,
      44,
      44,
      43,
      44,
      44,
      44,
      45,
      44,
      44,
      31,
      43,
      18,
      44,
      44,
      31,
      44,
      32,
      44,
      44,
      31,
      44,
      31,
      13,
      44,
      44,
      31
    ],
    "raw_completion_times": [
      44,
      44,
      44,
      44,
      44,
      31,
      44,
      44,
      44,
      44,
      44,
      44,
      44,
      44,
      43,
      31,
      43,
      44,
      43,
      44,
      44,
      44,
      44,
      44,
      43,
      44,
      44,
      44,
      45,
      44,
      44,
      31,
      43,
      44,
      44,
      31,
      44,
      32,
      44,
      44,
      31,
      44,
      31,
      44,
      44,
      31
    ],
    "raw_safety_achievement_times": [
      1,
      1
    ],
    "near_miss_frequency": 0.0,
    "safety_margin_analysis": "N/A",
    "performance_consistency": 24.018901184563536,
    "mean_comfort_score": 1.9999999999997442,
    "action_distribution": {
      "0": 265,
      "4": 55,
      "2": 1629,
      "3": 9
    }
  },
  "DQN": {
    "algorithm": "DQN",
    "n_episodes": 50,
    "success_rate": 0.32,
    "collision_rate": 0.68,
    "mean_reward": 29.380222463998486,
    "std_reward": 52.067939049151704,
    "mean_episode_length": 13.72,
    "mean_completion_time": 32.0,
    "mean_safety_achievement_time": 1.0,
    "reward_per_step": 2.14141563148677,
    "evaluation_time_seconds": 12.582908868789673,
    "consecutive_safe_episodes_max": 0,
    "total_successful_completions": 16,
    "total_collisions": 34,
    "mean_distance_traveled": 0.0,
    "raw_episode_rewards": [
      105.5044274347571,
      6.32390164891155,
      -3.7110554055073326,
      -6.931528866425993,
      -13.275774907877135,
      103.59127780474833,
      77.80977045824474,
      -3.712590174657846,
      1.6908348253981007,
      77.50977045824473,
      -3.7122595874663293,
      -3.7191281674458736,
      129.66225971748185,
      -3.7056752731731404,
      -3.7066554854184606,
      -6.961975270554885,
      -13.25937450407347,
      -6.583705303872274,
      -1.6185482270327096,
      -3.7184359385583594,
      103.59127780474833,
      -13.28421910948881,
      -13.283078612322324,
      -13.270775135550021,
      -6.967309104171039,
      -13.273915663460446,
      104.23977071753734,
      -3.7082146440754205,
      4.247569853961162,
      -13.27135596651723,
      104.98225016476235,
      -3.7055164610639384,
      104.98225016476235,
      30.774629494185803,
      -4.404756265655578,
      -3.7085672574298645,
      -13.259845869365606,
      -13.282201474156548,
      -6.9724553997968135,
      104.98225016476235,
      104.50008524340237,
      104.98225016476235,
      104.98225016476235,
      103.59127780474833,
      -6.674243980753883,
      123.56461681884676,
      -13.281987766150747,
      -13.276056979070674,
      104.50008524340237,
      -6.760476151413438
    ],
    "raw_episode_lengths": [
      31,
      10,
      6,
      5,
      2,
      31,
      39,
      6,
      10,
      39,
      6,
      6,
      31,
      6,
      6,
      5,
      2,
      5,
      7,
      6,
      31,
      2,
      2,
      2,
      5,
      2,
      31,
      6,
      9,
      2,
      31,
      6,
      31,
      15,
      6,
      6,
      2,
      2,
      5,
      31,
      31,
      31,
      31,
      31,
      5,
      31,
      2,
      2,
      31,
      5
    ],
    "raw_completion_times": [
      31,
      31,
      39,
      39,
      31,
      31,
      31,
      31,
      31,
      31,
      31,
      31,
      31,
      31,
      31,
      31
    ],
    "raw_safety_achievement_times": [
      1
    ],
    "near_miss_frequency": 0.0,
    "safety_margin_analysis": "N/A",
    "performance_consistency": 52.067939049151704,
    "mean_comfort_score": 0.1951473053946996,
    "action_distribution": {
      "1": 261,
      "0": 405,
      "4": 9,
      "3": 11
    }
  },
  "PPO": {
    "algorithm": "PPO",
    "n_episodes": 50,
    "success_rate": 0.94,
    "collision_rate": 0.06,
    "mean_reward": 97.73148581705911,
    "std_reward": 33.149568131839025,
    "mean_episode_length": 30.78,
    "mean_completion_time": 31.76595744680851,
    "mean_safety_achievement_time": 1.0,
    "reward_per_step": 3.1751619823605948,
    "evaluation_time_seconds": 26.82421875,
    "consecutive_safe_episodes_max": 9,
    "total_successful_completions": 47,
    "total_collisions": 3,
    "mean_distance_traveled": 0.0,
    "raw_episode_rewards": [
      89.6517181777734,
      75.78962027440147,
      121.61839670751891,
      101.82200493127985,
      82.76256786759993,
      89.6517181777734,
      107.41959605187392,
      113.4701256632759,
      92.90258058506424,
      141.08846528875864,
      89.95171817777339,
      91.26377825319103,
      101.95247356286647,
      144.1730681142151,
      82.76256786759993,
      109.31839714250481,
      110.14020412156756,
      144.1730681142151,
      76.99896124008472,
      148.98162804054496,
      89.95171817777339,
      89.6517181777734,
      111.46841462580021,
      89.6517181777734,
      102.00247356286647,
      116.59814844431725,
      89.6517181777734,
      89.6517181777734,
      77.7218224619599,
      75.2328913075969,
      89.6517181777734,
      -6.493003533159067,
      89.6517181777734,
      89.6517181777734,
      93.10258058506423,
      74.56683403954122,
      0.624288742188261,
      92.74144548065445,
      89.6517181777734,
      97.82198998874662,
      -0.0038438217784353412,
      135.41659759881293,
      89.6517181777734,
      129.41984287857522,
      121.14608930029613,
      144.1730681142151,
      144.1730681142151,
      89.95171817777339,
      148.98162804054496,
      125.21839660710818
    ],
    "raw_episode_lengths": [
      31,
      35,
      31,
      31,
      31,
      31,
      31,
      31,
      31,
      31,
      31,
      31,
      31,
      31,
      31,
      31,
      31,
      31,
      42,
      31,
      31,
      31,
      31,
      31,
      31,
      31,
      31,
      31,
      35,
      45,
      31,
      11,
      31,
      31,
      31,
      34,
      18,
      31,
      31,
      31,
      17,
      31,
      31,
      31,
      31,
      31,
      31,
      31,
      31,
      31
    ],
    "raw_completion_times": [
      31,
      35,
      31,
      31,
      31,
      31,
      31,
      31,
      31,
      31,
      31,
      31,
      31,
      31,
      31,
      31,
      31,
      31,
      42,
      31,
      31,
      31,
      31,
      31,
      31,
      31,
      31,
      31,
      35,
      45,
      31,
      31,
      31,
      31,
      34,
      31,
      31,
      31,
      31,
      31,
      31,
      31,
      31,
      31,
      31,
      31,
      31
    ],
    "raw_safety_achievement_times": [
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "near_miss_frequency": 0.0,
    "safety_margin_analysis": "N/A",
    "performance_consistency": 33.149568131839025,
    "mean_comfort_score": 1.9999975164757162,
    "action_distribution": {
      "4": 579,
      "3": 275,
      "0": 679,
      "2": 6
    }
  },
  "Q_Learning": {
    "algorithm": "Q_Learning",
    "n_episodes": 50,
    "success_rate": 0.94,
    "collision_rate": 0.06,
    "mean_reward": 93.37682939213755,
    "std_reward": 32.63298083528202,
    "mean_episode_length": 30.64,
    "mean_completion_time": 31.5531914893617,
    "mean_safety_achievement_time": 1.0,
    "reward_per_step": 3.047546651179424,
    "evaluation_time_seconds": 27.178966999053955,
    "consecutive_safe_episodes_max": 2,
    "total_successful_completions": 47,
    "total_collisions": 3,
    "mean_distance_traveled": 0.0,
    "raw_episode_rewards": [
      69.5796202743523,
      1.5681766071748129,
      89.97404909363541,
      89.97404909363541,
      98.62349111846726,
      134.2183629660355,
      79.07757944537839,
      85.17473644063028,
      73.53757663582238,
      72.23683403954722,
      107.31873961005061,
      90.3740490936354,
      71.56683403954122,
      107.31873961005061,
      85.37473644063029,
      125.03002096595944,
      73.2596202744029,
      134.2183629660355,
      75.21685047634449,
      69.28952408997682,
      90.424224739961,
      111.36615978051762,
      85.37473644063029,
      75.21685047634449,
      94.67413653402154,
      94.67413653402154,
      134.2183629660355,
      134.2183629660355,
      104.32349367197033,
      79.07757944537839,
      129.43695125899987,
      98.41873953548159,
      94.67413653402154,
      120.06615985508704,
      104.37349367197032,
      74.09685047641774,
      89.824224739961,
      134.7183629660355,
      134.2183629660355,
      71.16683403954121,
      134.2183629660355,
      69.97962027435229,
      69.97962027435229,
      1.5927921642062515,
      134.20145913402988,
      95.57328571457032,
      129.93695125899984,
      -3.3718380718929915,
      115.01874004641425,
      134.2183629660355
    ],
    "raw_episode_lengths": [
      32,
      18,
      31,
      31,
      31,
      31,
      31,
      31,
      31,
      35,
      31,
      31,
      34,
      31,
      31,
      31,
      36,
      31,
      32,
      37,
      31,
      31,
      31,
      32,
      31,
      31,
      31,
      31,
      31,
      31,
      31,
      31,
      31,
      31,
      31,
      31,
      31,
      31,
      31,
      34,
      31,
      32,
      32,
      18,
      31,
      31,
      31,
      13,
      31,
      31
    ],
    "raw_completion_times": [
      32,
      31,
      31,
      31,
      31,
      31,
      31,
      31,
      35,
      31,
      31,
      34,
      31,
      31,
      31,
      36,
      31,
      32,
      37,
      31,
      31,
      31,
      32,
      31,
      31,
      31,
      31,
      31,
      31,
      31,
      31,
      31,
      31,
      31,
      31,
      31,
      31,
      31,
      34,
      31,
      32,
      32,
      31,
      31,
      31,
      31,
      31
    ],
    "raw_safety_achievement_times": [
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1,
      1
    ],
    "near_miss_frequency": 0.0,
    "safety_margin_analysis": "N/A",
    "performance_consistency": 32.63298083528202,
    "mean_comfort_score": 1.9999999978805363,
    "action_distribution": {
      "4": 873,
      "2": 102,
      "1": 44,
      "3": 371,
      "0": 142
    }
  }
}